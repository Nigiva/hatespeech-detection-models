{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jigsaw 2017 - RoBERTa BCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables d'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# Id des GPU disponibles : 0 et 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from typing import Any, Union, Dict, List\n",
    "import uuid\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchtext\n",
    "import nltk\n",
    "import sklearn\n",
    "import transformers\n",
    "import torchmetrics as tm\n",
    "from torchmetrics import MetricCollection, Metric, Accuracy, Precision, Recall, AUROC, HammingDistance, F1Score, ROC, AUC, PrecisionRecallCurve\n",
    "\n",
    "\n",
    "from loguru import logger\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOME_NAME = \"jigsaw2017-roberta-bce\"\n",
    "\n",
    "# Dataset\n",
    "DATA_DIR_PATH = os.path.abspath(\"../../data\")\n",
    "TRAIN_DATASET_PATH = os.path.join(DATA_DIR_PATH, \"jigsaw2017-train.csv\")\n",
    "TEST_DATASET_PATH = os.path.join(DATA_DIR_PATH, \"jigsaw2017-test.csv\")\n",
    "VALID_DATASET_PATH = os.path.join(DATA_DIR_PATH, \"jigsaw2017-valid.csv\")\n",
    "LABEL_LIST = ['toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "            'insult', 'identity_hate']\n",
    "\n",
    "# Session\n",
    "SESSION_DIR_PATH = os.path.abspath(\"../../session\")\n",
    "SESSION_DATETIME = datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S-%f\")\n",
    "SESSION_NAME = f\"{CUSTOME_NAME}_{SESSION_DATETIME}\"\n",
    "CURRENT_SESSION_DIR_PATH = os.path.join(SESSION_DIR_PATH, SESSION_NAME)\n",
    "# Créer le dossier de la session\n",
    "os.makedirs(CURRENT_SESSION_DIR_PATH, exist_ok=True)\n",
    "\n",
    "# Architecture de fichier dans `CURRENT_SESSION_DIR_PATH`\n",
    "LOG_FILE_NAME = f\"{SESSION_NAME}.loguru.log\"\n",
    "MODEL_FILE_NAME = f\"{SESSION_NAME}.model\"\n",
    "TEST_FILE_NAME = f\"{SESSION_NAME}.test.csv\"\n",
    "METRIC_FILE_NAME = f\"{SESSION_NAME}.metric.json\"\n",
    "LOG_FILE_PATH = os.path.join(CURRENT_SESSION_DIR_PATH, LOG_FILE_NAME)\n",
    "MODEL_FILE_PATH = os.path.join(CURRENT_SESSION_DIR_PATH, MODEL_FILE_NAME)\n",
    "TEST_FILE_PATH = os.path.join(CURRENT_SESSION_DIR_PATH, TEST_FILE_NAME)\n",
    "METRIC_FILE_PATH = os.path.join(CURRENT_SESSION_DIR_PATH, METRIC_FILE_NAME)\n",
    "\n",
    "# CUDA\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 18:23:00.675 | INFO     | __main__:<cell line: 2>:2 - SESSION_NAME='jigsaw2017-roberta-bce_2022-03-28T18-23-00-343919'\n",
      "2022-03-28 18:23:00.677 | INFO     | __main__:<cell line: 3>:3 - TRAIN_DATASET_PATH='/work2/home/ing1/corentin/hatespeech-detection-models/data/jigsaw2017-train.csv'\n",
      "2022-03-28 18:23:00.678 | INFO     | __main__:<cell line: 4>:4 - TEST_DATASET_PATH='/work2/home/ing1/corentin/hatespeech-detection-models/data/jigsaw2017-test.csv'\n",
      "2022-03-28 18:23:00.680 | INFO     | __main__:<cell line: 5>:5 - CURRENT_SESSION_DIR_PATH='/work2/home/ing1/corentin/hatespeech-detection-models/session/jigsaw2017-roberta-bce_2022-03-28T18-23-00-343919'\n",
      "2022-03-28 18:23:00.681 | INFO     | __main__:<cell line: 6>:6 - LABEL_LIST=['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
     ]
    }
   ],
   "source": [
    "logger.add(LOG_FILE_PATH, level=\"TRACE\")\n",
    "logger.info(f\"{SESSION_NAME=}\")\n",
    "logger.info(f\"{TRAIN_DATASET_PATH=}\")\n",
    "logger.info(f\"{TEST_DATASET_PATH=}\")\n",
    "logger.info(f\"{CURRENT_SESSION_DIR_PATH=}\")\n",
    "logger.info(f\"{LABEL_LIST=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérifier la cohérence de l'architecture et l'accès aux ressources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 18:23:00.995 | INFO     | __main__:<cell line: 1>:1 - Checking consistency...\n",
      "2022-03-28 18:23:00.997 | SUCCESS  | __main__:<cell line: 10>:10 - Datasets are reachable\n",
      "2022-03-28 18:23:00.998 | INFO     | __main__:<cell line: 15>:15 - GPU_IS_AVAILABLE=True\n",
      "2022-03-28 18:23:00.999 | INFO     | __main__:<cell line: 16>:16 - GPU_COUNT=1\n",
      "2022-03-28 18:23:01.001 | SUCCESS  | __main__:<cell line: 20>:20 - GPU and CUDA are available\n",
      "2022-03-28 18:23:01.002 | INFO     | __main__:<cell line: 21>:21 - device=device(type='cuda')\n",
      "2022-03-28 18:23:01.005 | INFO     | __main__:<cell line: 22>:24 - GPU 0 : NVIDIA TITAN X (Pascal)\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Checking consistency...\")\n",
    "\n",
    "# Vérifier l'accès aux datasets\n",
    "if not os.path.exists(TRAIN_DATASET_PATH):\n",
    "    logger.critical(f\"Train dataset does not exist !\")\n",
    "    raise RuntimeError(\"Train dataset does not exist !\")\n",
    "if not os.path.exists(TEST_DATASET_PATH):\n",
    "    logger.critical(f\"Test dataset does not exist !\")\n",
    "    raise RuntimeError(\"Test dataset does not exist !\")\n",
    "logger.success(\"Datasets are reachable\")\n",
    "\n",
    "# Vérifier l'accès aux GPU\n",
    "GPU_IS_AVAILABLE = torch.cuda.is_available()\n",
    "GPU_COUNT = torch.cuda.device_count()\n",
    "logger.info(f\"{GPU_IS_AVAILABLE=}\")\n",
    "logger.info(f\"{GPU_COUNT=}\")\n",
    "if not GPU_IS_AVAILABLE:\n",
    "    logger.critical(\"GPU and CUDA are not available !\")\n",
    "    raise RuntimeError(\"GPU and CUDA are not available !\")\n",
    "logger.success(\"GPU and CUDA are available\")\n",
    "logger.info(f\"{device=}\")\n",
    "for gpu_id in range(GPU_COUNT):\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    logger.info(f\"GPU {gpu_id} : {gpu_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 18:23:02.123 | SUCCESS  | __main__:<cell line: 2>:2 - Dataset loaded !\n"
     ]
    }
   ],
   "source": [
    "all_train_df = pd.read_csv(TRAIN_DATASET_PATH, index_col=0)\n",
    "logger.success(\"Dataset loaded !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = all_train_df\n",
    "validation_df = pd.read_csv(VALID_DATASET_PATH, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawDataset(Dataset):\n",
    "    def __init__(self, data_df, tokenizer):\n",
    "        self.data = data_df\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        comment = self.data.iloc[index][\"comment_text\"]\n",
    "        label = torch.tensor(self.data.iloc[index][LABEL_LIST].tolist(), dtype=torch.float)\n",
    "        \n",
    "        token_list, attention_mask = self.text_to_token_and_mask(comment)\n",
    "\n",
    "        return dict(index=index, ids=token_list, mask=attention_mask, labels=label)\n",
    "    \n",
    "    def text_to_token_and_mask(self, input_text):\n",
    "        tokenization_dict = tokenizer.encode_plus(input_text,\n",
    "                                add_special_tokens=True,\n",
    "                                max_length=128,\n",
    "                                padding='max_length',\n",
    "                                truncation=True,\n",
    "                                return_attention_mask=True,\n",
    "                                return_tensors='pt')\n",
    "        token_list = tokenization_dict[\"input_ids\"].flatten()\n",
    "        attention_mask = tokenization_dict[\"attention_mask\"].flatten()\n",
    "        return (token_list, attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_lr(optim, lr):\n",
    "    '''\n",
    "    Set the learning rate in the optimizer\n",
    "    '''\n",
    "    for g in optim.param_groups:\n",
    "        g['lr'] = lr\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer class and functions for models and predictions\n",
    "\n",
    "class TransformerClassifierStack(nn.Module):\n",
    "    def __init__(self, tr_model, nb_labels, dropout_prob=0.4, freeze=False):\n",
    "        super().__init__()\n",
    "        self.tr_model = tr_model\n",
    "\n",
    "        # Stack features of 4 last encoders\n",
    "        self.hidden_dim = tr_model.config.hidden_size * 4\n",
    "\n",
    "        # hidden linear for the classification\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.hl = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "\n",
    "        # Last Linear for the classification\n",
    "        self.last_l = nn.Linear(self.hidden_dim, nb_labels)\n",
    "\n",
    "        # freeze all the parameters if necessary\n",
    "        for param in self.tr_model.parameters():\n",
    "            param.requires_grad = not freeze\n",
    "\n",
    "        # init learning params of last layers\n",
    "        torch.nn.init.xavier_uniform_(self.hl.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.last_l.weight)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        # ids = [batch_size, padded_seq_len]\n",
    "        # mask = [batch_size, padded_seq_len]\n",
    "        # mask: avoid to make self attention on padded data\n",
    "        tr_output = self.tr_model(input_ids=ids,\n",
    "                                  attention_mask=mask,\n",
    "                                  output_hidden_states=True)\n",
    "\n",
    "        # Get all the hidden states\n",
    "        hidden_states = tr_output['hidden_states']\n",
    "\n",
    "        # hs_* = [batch_size, padded_seq_len, 768]\n",
    "        hs_1 = hidden_states[-1][:, 0, :]\n",
    "        hs_2 = hidden_states[-2][:, 0, :]\n",
    "        hs_3 = hidden_states[-3][:, 0, :]\n",
    "        hs_4 = hidden_states[-4][:, 0, :]\n",
    "\n",
    "        # features_vec = [batch_size, 768 * 4]\n",
    "        features_vec = torch.cat([hs_1, hs_2, hs_3, hs_4], dim=-1)\n",
    "\n",
    "        x = self.dropout(features_vec)\n",
    "        x = self.hl(x)\n",
    "\n",
    "        # x = [batch_size, 768 * 4]\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.last_l(x)\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        # x = [batch_size, 1]\n",
    "        return x\n",
    "\n",
    "def load_roberta_model(nb_labels):\n",
    "    '''\n",
    "    Load RoBERTa model without any checkpoint\n",
    "    RoBERTa for finetuning\n",
    "    '''\n",
    "    logger.info(f\"transformers.RobertaTokenizer : roberta-base\")\n",
    "    logger.info(f\"transformers.AutoModel : roberta-base\")\n",
    "    tokenizer = transformers.RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    tr_model = transformers.AutoModel.from_pretrained('roberta-base')\n",
    "    model = TransformerClassifierStack(tr_model, nb_labels, freeze=True)\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def load_roberta_pretrained(path, nb_labels, lr=2e-5):\n",
    "    '''\n",
    "    Load RoBERTa from checkout point (already trained on Hate Speech tasks)\n",
    "    '''\n",
    "    tokenizer = transformers.RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    tr_model = transformers.AutoModel.from_pretrained('roberta-base')\n",
    "    model = TransformerClassifierStack(tr_model, nb_labels)\n",
    "\n",
    "    loaded = torch.load(path)\n",
    "    model.load_state_dict(loaded['state_dict'])\n",
    "\n",
    "    optimizer = transformers.AdamW(model.parameters(), lr=lr)\n",
    "    optimizer.load_state_dict(loaded['optimizer_dict'])\n",
    "    optimizer = set_lr(optimizer, lr)\n",
    "\n",
    "    return model, tokenizer, optimizer\n",
    "\n",
    "def preds_fn(batch, model, device):\n",
    "    '''\n",
    "    Get the predictions for one batch according to the model\n",
    "    '''\n",
    "    b_input = batch['ids'].to(device)\n",
    "    b_mask = batch['mask'].to(device)\n",
    "\n",
    "    return model(b_input, b_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 18:23:03.640 | INFO     | __main__:load_roberta_model:63 - transformers.RobertaTokenizer : roberta-base\n",
      "2022-03-28 18:23:03.642 | INFO     | __main__:load_roberta_model:64 - transformers.AutoModel : roberta-base\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2022-03-28 18:23:07.993 | SUCCESS  | __main__:<cell line: 3>:3 - Model loaded !\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model, tokenizer = load_roberta_model(nb_labels=len(LABEL_LIST))\n",
    "logger.success(\"Model loaded !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparamètre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 18:23:08.193 | INFO     | __main__:<cell line: 7>:7 - BATCH_SIZE=32\n",
      "2022-03-28 18:23:08.195 | INFO     | __main__:<cell line: 8>:8 - LR=0.0001\n",
      "2022-03-28 18:23:08.196 | INFO     | __main__:<cell line: 9>:9 - PIN_MEMORY=True\n",
      "2022-03-28 18:23:08.198 | INFO     | __main__:<cell line: 10>:10 - NUM_WORKERS=0\n",
      "2022-03-28 18:23:08.201 | INFO     | __main__:<cell line: 11>:11 - PREFETCH_FACTOR=2\n",
      "2022-03-28 18:23:08.202 | INFO     | __main__:<cell line: 12>:12 - NUM_EPOCHS=1\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "LR=1e-4\n",
    "PIN_MEMORY = True\n",
    "NUM_WORKERS = 0\n",
    "PREFETCH_FACTOR = 2\n",
    "NUM_EPOCHS = 3\n",
    "logger.info(f\"{BATCH_SIZE=}\")\n",
    "logger.info(f\"{LR=}\")\n",
    "logger.info(f\"{PIN_MEMORY=}\")\n",
    "logger.info(f\"{NUM_WORKERS=}\")\n",
    "logger.info(f\"{PREFETCH_FACTOR=}\")\n",
    "logger.info(f\"{NUM_EPOCHS=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 18:23:08.545 | INFO     | __main__:<cell line: 19>:19 - BCELoss()\n",
      "2022-03-28 18:23:08.550 | INFO     | __main__:<cell line: 21>:21 - AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BCELoss()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = JigsawDataset(train_df, tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=True,\n",
    "                             num_workers=NUM_WORKERS,\n",
    "                             prefetch_factor=PREFETCH_FACTOR,\n",
    "                             pin_memory=PIN_MEMORY)\n",
    "\n",
    "validation_dataset = JigsawDataset(validation_df, tokenizer)\n",
    "validation_dataloader = DataLoader(validation_dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=True,\n",
    "                             num_workers=NUM_WORKERS,\n",
    "                             prefetch_factor=PREFETCH_FACTOR,\n",
    "                             pin_memory=PIN_MEMORY)\n",
    "\n",
    "# Pas besoin de Sigmoid en sorti du model seulement pour `BCEWithLogitsLoss`\n",
    "criterion = torch.nn.BCELoss()\n",
    "logger.info(criterion)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "logger.info(optimizer)\n",
    "\n",
    "model.to(device)\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variantes de Hamming Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HammingLossWithoutThreshold(Metric):\n",
    "    def __init__(self, num_classes=1, dist_sync_on_step=False):\n",
    "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.add_state(\"total\", default=torch.tensor(0, dtype=torch.float32), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"nbr_sample\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "        current_nbr_sample, current_nbr_category = preds.shape\n",
    "        if current_nbr_category != self.num_classes:\n",
    "          raise AttributeError(\"`num_classes` != `current_nbr_category` detected in `pred` parameter\")\n",
    "        \n",
    "        current_loss_per_pred = torch.absolute(target - preds)\n",
    "        current_hamming_loss = current_loss_per_pred.sum()\n",
    "\n",
    "        self.total += current_hamming_loss.float()\n",
    "        self.nbr_sample += current_nbr_sample\n",
    "\n",
    "    def compute(self):\n",
    "        return self.total/(self.num_classes*self.nbr_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RebalancedHammingLossWithoutThreshold(Metric):\n",
    "    def __init__(self, num_classes=1, average=\"macro\", dist_sync_on_step=False):\n",
    "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # average = \"macro\" or None\n",
    "        self.average = average\n",
    "\n",
    "        # Nombre de positif 1 & negatif 0 par categorie\n",
    "        self.add_state(\n",
    "            \"number_positive\",\n",
    "            default=torch.tensor([0 for _ in range(num_classes)]),\n",
    "            dist_reduce_fx=\"sum\",\n",
    "        )\n",
    "        self.add_state(\n",
    "            \"number_negative\",\n",
    "            default=torch.tensor([0 for _ in range(num_classes)]),\n",
    "            dist_reduce_fx=\"sum\",\n",
    "        )\n",
    "\n",
    "        self.add_state(\n",
    "            \"hamming_loss_positive\",\n",
    "            default=torch.tensor([0.0 for _ in range(num_classes)]),\n",
    "            dist_reduce_fx=\"sum\",\n",
    "        )\n",
    "        self.add_state(\n",
    "            \"hamming_loss_negative\",\n",
    "            default=torch.tensor([0.0 for _ in range(num_classes)]),\n",
    "            dist_reduce_fx=\"sum\",\n",
    "        )\n",
    "\n",
    "        self.add_state(\"nbr_sample\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "        current_nbr_sample, current_nbr_category = preds.shape\n",
    "        if current_nbr_category != self.num_classes:\n",
    "            raise AttributeError(\n",
    "                \"`num_classes` != `current_nbr_category` detected in `pred` parameter\"\n",
    "            )\n",
    "\n",
    "        # Nombre de positif 1 & negatif 0 par categorie\n",
    "        current_number_positive = target.sum(axis=0)\n",
    "        current_number_negative = current_nbr_sample - target.sum(axis=0)\n",
    "\n",
    "        self.number_positive += current_number_positive.int()\n",
    "        self.number_negative += current_number_negative.int()\n",
    "\n",
    "        self.nbr_sample += current_nbr_sample\n",
    "\n",
    "        for class_id in range(self.num_classes):\n",
    "            positive_filter = target[:, class_id] == 1\n",
    "            negative_filter = target[:, class_id] == 0\n",
    "\n",
    "            target_vector = target[:, class_id]\n",
    "            preds_vector = preds[:, class_id]\n",
    "\n",
    "            # Filtered vector\n",
    "            ## Target\n",
    "            pos_filtered_target_vector = target_vector[positive_filter]\n",
    "            neg_filtered_target_vector = target_vector[negative_filter]\n",
    "            ## Preds\n",
    "            pos_filtered_preds_vector = preds_vector[positive_filter]\n",
    "            neg_filtered_preds_vector = preds_vector[negative_filter]\n",
    "\n",
    "            # Hamming Loss without Threshold\n",
    "            hamming_loss_on_positive = torch.absolute(\n",
    "                pos_filtered_target_vector - pos_filtered_preds_vector\n",
    "            )\n",
    "            hamming_loss_on_negative = torch.absolute(\n",
    "                neg_filtered_target_vector - neg_filtered_preds_vector\n",
    "            )\n",
    "\n",
    "            self.hamming_loss_positive[class_id] += hamming_loss_on_positive.sum()\n",
    "            self.hamming_loss_negative[class_id] += hamming_loss_on_negative.sum()\n",
    "\n",
    "    def compute(self):\n",
    "        factor_pos = self.nbr_sample / (2 * self.number_positive)\n",
    "        factor_neg = self.nbr_sample / (2 * self.number_negative)\n",
    "\n",
    "        rebalanced_hamming_loss_per_class = torch.multiply(\n",
    "            self.hamming_loss_positive, factor_pos\n",
    "        ) + torch.multiply(self.hamming_loss_negative, factor_neg)\n",
    "        if self.average == \"macro\":\n",
    "            return rebalanced_hamming_loss_per_class.sum() / (\n",
    "                self.nbr_sample * self.num_classes\n",
    "            )\n",
    "        return rebalanced_hamming_loss_per_class / (self.nbr_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciation des metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(LABEL_LIST)\n",
    "train_metric_dict = dict()\n",
    "\n",
    "# AUROC Macro\n",
    "auroc_macro = AUROC(num_classes=num_classes, compute_on_step=True, average=\"macro\")\n",
    "train_metric_dict[\"auroc_macro\"] = auroc_macro\n",
    "\n",
    "# AUROC per class\n",
    "auroc_per_class = AUROC(num_classes=num_classes, compute_on_step=True, average=None)\n",
    "train_metric_dict[\"auroc_per_class\"] = auroc_per_class\n",
    "\n",
    "# F1 score global\n",
    "f1 = F1Score()\n",
    "train_metric_dict[\"f1\"] = f1\n",
    "\n",
    "# F1 score per class\n",
    "f1_per_calss = F1Score(num_classes=6, average=None)\n",
    "train_metric_dict[\"f1_per_calss\"] = f1_per_calss\n",
    "\n",
    "# Hamming Distance without Threshold\n",
    "hamming_loss_woutt = HammingLossWithoutThreshold(num_classes=num_classes)\n",
    "train_metric_dict[\"hamming_loss_without_threshold\"] = hamming_loss_woutt\n",
    "\n",
    "# Rebalanced Hamming Distance without Threshold macro\n",
    "rebalanced_hamming_loss_woutt_macro = RebalancedHammingLossWithoutThreshold(\n",
    "    num_classes=num_classes, average=\"macro\"\n",
    ")\n",
    "train_metric_dict[\n",
    "    \"rebalanced_hamming_loss_without_threshold_macro\"\n",
    "] = rebalanced_hamming_loss_woutt_macro\n",
    "\n",
    "# Rebalanced Hamming Distance without Threshold macro\n",
    "rebalanced_hamming_loss_woutt_per_class = RebalancedHammingLossWithoutThreshold(\n",
    "    num_classes=num_classes, average=None\n",
    ")\n",
    "train_metric_dict[\n",
    "    \"rebalanced_hamming_loss_without_threshold_per_class\"\n",
    "] = rebalanced_hamming_loss_woutt_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetricCollection(\n",
       "  (auroc_macro): AUROC()\n",
       "  (auroc_per_class): AUROC()\n",
       "  (f1): F1Score()\n",
       "  (f1_per_calss): F1Score()\n",
       "  (hamming_loss_without_threshold): HammingLossWithoutThreshold()\n",
       "  (rebalanced_hamming_loss_without_threshold_macro): RebalancedHammingLossWithoutThreshold()\n",
       "  (rebalanced_hamming_loss_without_threshold_per_class): RebalancedHammingLossWithoutThreshold()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metric = MetricCollection(train_metric_dict)\n",
    "train_metric.to(device)\n",
    "\n",
    "validation_metric = train_metric.clone()\n",
    "validation_metric.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize(object_to_serialize: Any, ensure_ascii: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Serialize any object, i.e. convert an object to JSON\n",
    "    Args:\n",
    "        object_to_serialize (Any): The object to serialize\n",
    "        ensure_ascii (bool, optional): If ensure_ascii is true (the default), the output is guaranteed to have all incoming non-ASCII characters escaped. If ensure_ascii is false, these characters will be output as-is. Defaults to True.\n",
    "    Returns:\n",
    "            str: string of serialized object (JSON)\n",
    "    \"\"\"\n",
    "\n",
    "    def dumper(obj: Any) -> Union[str, Dict]:\n",
    "        \"\"\"\n",
    "        Function called recursively by json.dumps to know how to serialize an object.\n",
    "        For example, for datetime, we try to convert it to ISO format rather than\n",
    "        retrieve the list of attributes defined in its object.\n",
    "        Args:\n",
    "            obj (Any): The object to serialize\n",
    "        Returns:\n",
    "            Union[str, Dict]: Serialized object\n",
    "        \"\"\"\n",
    "        if isinstance(obj, torch.Tensor):\n",
    "            return obj.cpu().numpy().tolist()\n",
    "        elif hasattr(obj, \"__dict__\"):\n",
    "            return obj.__dict__\n",
    "        return str(obj)\n",
    "\n",
    "    return json.dumps(object_to_serialize, default=dumper, ensure_ascii=ensure_ascii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_metric(metric_collection, **kwargs):\n",
    "    \"\"\"\n",
    "    Export MetricCollection to json file\n",
    "\n",
    "    Args:\n",
    "        metric_collection: MetricCollection\n",
    "        **kwargs: field to add in json line\n",
    "    \"\"\"\n",
    "    with open(METRIC_FILE_PATH, \"a\") as f:\n",
    "        metric_collection_value = metric_collection.compute()\n",
    "        metric_collection_value.update(kwargs)\n",
    "        serialized_value = serialize(metric_collection_value)\n",
    "        f.write(serialized_value)\n",
    "        f.write(\"\\n\")\n",
    "    logger.success(\"Metrics are exported !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(epoch_id=None):\n",
    "    model.train()\n",
    "    logger.info(f\"START EPOCH {epoch_id=}\")\n",
    "\n",
    "    progress = tqdm(train_dataloader, desc='training batch...', leave=False)\n",
    "    for batch_id, batch in enumerate(progress):\n",
    "        if batch_id % 1_000 == 0:\n",
    "            valid_epoch(epoch_id=epoch, batch_id=batch_id)\n",
    "        \n",
    "        logger.trace(f\"{batch_id=}\")\n",
    "        token_list_batch = batch[\"ids\"].to(device)\n",
    "        attention_mask_batch = batch[\"mask\"].to(device)\n",
    "        label_batch = batch[\"labels\"].to(device)\n",
    "\n",
    "        # Reset gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Predict\n",
    "        prediction_batch = model(token_list_batch, attention_mask_batch)\n",
    "        transformed_prediction_batch = prediction_batch.squeeze()\n",
    "\n",
    "        # Loss\n",
    "        loss = criterion(transformed_prediction_batch.to(torch.float32), label_batch.to(torch.float32))\n",
    "\n",
    "        # Metrics\n",
    "        train_metrics_collection_dict = train_metric(transformed_prediction_batch.to(torch.float32), label_batch.to(torch.int32))\n",
    "        logger.trace(train_metrics_collection_dict)\n",
    "\n",
    "        # Backprop\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        loss.backward()\n",
    "        # gradient clip\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar description\n",
    "        progress_description = \"Train Loss : {loss:.4f} - Train AUROC : {acc:.4f}\"\n",
    "        auroc_macro_value = float(train_metrics_collection_dict[\"auroc_macro\"])\n",
    "        progress_description = progress_description.format(loss=loss.item(), acc=auroc_macro_value)\n",
    "        progress.set_description(progress_description)\n",
    "\n",
    "    logger.info(f\"END EPOCH {epoch_id=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ffc77bbae74cff9b986997f25521b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training batch...:   0%|          | 0/3989 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=True,\n",
    "                             num_workers=NUM_WORKERS,\n",
    "                             prefetch_factor=PREFETCH_FACTOR,\n",
    "                             pin_memory=PIN_MEMORY,\n",
    "                             drop_last=True)\n",
    "\n",
    "ts = torch.Size([32, 6])\n",
    "drop_last=True\n",
    "progress = tqdm(train_dataloader, desc='training batch...', leave=False)\n",
    "for batch in progress:\n",
    "    label_batch = batch[\"labels\"].to(device)\n",
    "    if label_batch.shape != ts:\n",
    "        print(label_batch.shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_epoch(epoch_id=None, batch_id=None):\n",
    "    model.eval()\n",
    "    logger.info(f\"START VALIDATION {epoch_id=}{batch_id=}\")\n",
    "    validation_metric.reset()\n",
    "\n",
    "    loss_list = []\n",
    "    prediction_list = torch.Tensor([])\n",
    "    target_list = torch.Tensor([])\n",
    "\n",
    "\n",
    "    progress = tqdm(validation_dataloader, desc=\"valid batch...\", leave=False)\n",
    "    for _, batch in enumerate(progress):\n",
    "        \n",
    "        token_list_batch = batch[\"ids\"].to(device)\n",
    "        attention_mask_batch = batch[\"mask\"].to(device)\n",
    "        label_batch = batch[\"labels\"].to(device)\n",
    "\n",
    "        # Predict\n",
    "        prediction_batch = model(token_list_batch, attention_mask_batch)\n",
    "\n",
    "        transformed_prediction_batch = prediction_batch.squeeze()\n",
    "\n",
    "        # Loss\n",
    "        loss = criterion(\n",
    "            transformed_prediction_batch.to(torch.float32),\n",
    "            label_batch.to(torch.float32),\n",
    "        )\n",
    "        loss_list.append(loss.item())\n",
    "        prediction_list = torch.concat(\n",
    "            [prediction_list, transformed_prediction_batch.cpu()]\n",
    "        )\n",
    "        target_list = torch.concat([target_list, label_batch.cpu()])\n",
    "\n",
    "        # Metrics\n",
    "        validation_metric(transformed_prediction_batch.to(torch.float32), label_batch.to(torch.int32))\n",
    "\n",
    "    loss_mean = np.mean(loss_list)\n",
    "    logger.trace(validation_metric.compute())\n",
    "    logger.info(f\"END VALIDATION {epoch_id=}{batch_id=}\")\n",
    "    export_metric(validation_metric, epoch_id=epoch_id, batch_id=batch_id, loss=loss_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534e01625c58431ea38a9f699a87accd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training epoch...:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 18:23:13.491 | INFO     | __main__:train_epoch:3 - START EPOCH epoch_id=1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a0f93ae30f40a3b900fd7bfe7d0651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training batch...:   0%|          | 0/3990 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 18:23:13.586 | INFO     | __main__:valid_epoch:4 - START VALIDATION epoch_id=1batch_id=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c132dcabb9484a64903fb1ea8ff12d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "valid batch...:   0%|          | 0/998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 18:26:23.892 | INFO     | __main__:valid_epoch:40 - END VALIDATION epoch_id=1batch_id=0\n",
      "2022-03-28 18:26:23.894 | SUCCESS  | __main__:export_metric:15 - Metrics are exported !\n",
      "2022-03-28 18:29:48.650 | INFO     | __main__:valid_epoch:4 - START VALIDATION epoch_id=1batch_id=1000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251e542d47f649deb3c22ae60167237e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "valid batch...:   0%|          | 0/998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 18:32:55.034 | INFO     | __main__:valid_epoch:40 - END VALIDATION epoch_id=1batch_id=1000\n",
      "2022-03-28 18:32:55.036 | SUCCESS  | __main__:export_metric:15 - Metrics are exported !\n",
      "2022-03-28 18:36:19.859 | INFO     | __main__:valid_epoch:4 - START VALIDATION epoch_id=1batch_id=2000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0a1303b1fe42fba39ec3652ea4a365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "valid batch...:   0%|          | 0/998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 18:39:25.743 | INFO     | __main__:valid_epoch:40 - END VALIDATION epoch_id=1batch_id=2000\n",
      "2022-03-28 18:39:25.744 | SUCCESS  | __main__:export_metric:15 - Metrics are exported !\n",
      "2022-03-28 18:42:47.740 | INFO     | __main__:valid_epoch:4 - START VALIDATION epoch_id=1batch_id=3000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54c4f00c77e4df593d2f5b396f70709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "valid batch...:   0%|          | 0/998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 18:45:52.116 | INFO     | __main__:valid_epoch:40 - END VALIDATION epoch_id=1batch_id=3000\n",
      "2022-03-28 18:45:52.117 | SUCCESS  | __main__:export_metric:15 - Metrics are exported !\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([1, 6])) that is different to the input size (torch.Size([6])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m progress \u001b[39m=\u001b[39m  tqdm(\u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,NUM_EPOCHS\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m), desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtraining epoch...\u001b[39m\u001b[39m'\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m progress:\n\u001b[1;32m      4\u001b[0m     \u001b[39m# Train\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     train_epoch(epoch_id\u001b[39m=\u001b[39;49mepoch)\n\u001b[1;32m      7\u001b[0m     \u001b[39m# Validation\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     valid_epoch(epoch_id\u001b[39m=\u001b[39mepoch)\n",
      "\u001b[1;32m/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb Cell 35'\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(epoch_id)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000036vscode-remote?line=19'>20</a>\u001b[0m transformed_prediction_batch \u001b[39m=\u001b[39m prediction_batch\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000036vscode-remote?line=21'>22</a>\u001b[0m \u001b[39m# Loss\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000036vscode-remote?line=22'>23</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(transformed_prediction_batch\u001b[39m.\u001b[39;49mto(torch\u001b[39m.\u001b[39;49mfloat32), label_batch\u001b[39m.\u001b[39;49mto(torch\u001b[39m.\u001b[39;49mfloat32))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000036vscode-remote?line=24'>25</a>\u001b[0m \u001b[39m# Metrics\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000036vscode-remote?line=25'>26</a>\u001b[0m train_metrics_collection_dict \u001b[39m=\u001b[39m train_metric(transformed_prediction_batch\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32), label_batch\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mint32))\n",
      "File \u001b[0;32m~/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:612\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py?line=610'>611</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py?line=611'>612</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbinary_cross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[0;32m~/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/nn/functional.py:3056\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/nn/functional.py?line=3053'>3054</a>\u001b[0m     reduction_enum \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/nn/functional.py?line=3054'>3055</a>\u001b[0m \u001b[39mif\u001b[39;00m target\u001b[39m.\u001b[39msize() \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize():\n\u001b[0;32m-> <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/nn/functional.py?line=3055'>3056</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/nn/functional.py?line=3056'>3057</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing a target size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) that is different to the input size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) is deprecated. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/nn/functional.py?line=3057'>3058</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease ensure they have the same size.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(target\u001b[39m.\u001b[39msize(), \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/nn/functional.py?line=3058'>3059</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/nn/functional.py?line=3060'>3061</a>\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/nn/functional.py?line=3061'>3062</a>\u001b[0m     new_size \u001b[39m=\u001b[39m _infer_size(target\u001b[39m.\u001b[39msize(), weight\u001b[39m.\u001b[39msize())\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([1, 6])) that is different to the input size (torch.Size([6])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "progress =  tqdm(range(1,NUM_EPOCHS+1), desc='training epoch...', leave=True)\n",
    "for epoch in progress:\n",
    "    # Train\n",
    "    train_epoch(epoch_id=epoch)\n",
    "\n",
    "    # Validation\n",
    "    valid_epoch(epoch_id=epoch)\n",
    "\n",
    "    # Save\n",
    "    torch.save(model, MODEL_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del train_df\n",
    "    del validation_df\n",
    "except NameError:\n",
    "    logger.warning(\"Train DataFrame & Validation DataFrame already deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(TEST_DATASET_PATH, index_col=0)\n",
    "test_df = test_df[~test_df.comment_text.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = JigsawDataset(test_df, tokenizer)\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                             batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluation(model):\n",
    "    model.eval()\n",
    "    logger.info(f\"START EVALUATION\")\n",
    "\n",
    "    index_tensor = torch.Tensor([])\n",
    "    prediction_tensor = torch.Tensor([])\n",
    "\n",
    "    progress = tqdm(test_dataloader, desc='test batch...', leave=False)\n",
    "    for batch_id, batch in enumerate(progress):\n",
    "        logger.trace(f\"{batch_id=}\")\n",
    "        index_batch = batch[\"index\"].to(device)\n",
    "        token_list_batch = batch[\"ids\"].to(device)\n",
    "        attention_mask_batch = batch[\"mask\"].to(device)\n",
    "        label_batch = batch[\"labels\"].to(device)\n",
    "\n",
    "        # Predict\n",
    "        prediction_batch = model(token_list_batch, attention_mask_batch)\n",
    "        transformed_prediction_batch = prediction_batch.squeeze()\n",
    "        \n",
    "        index_tensor = torch.concat([index_tensor, index_batch.cpu()])\n",
    "        prediction_tensor = torch.concat([prediction_tensor, transformed_prediction_batch.cpu()])\n",
    "    \n",
    "    logger.info(f\"END EVALUATION\")\n",
    "    prediction_test_df = pd.DataFrame(prediction_tensor.tolist(), \n",
    "                                     columns=LABEL_LIST,\n",
    "                                     index=index_tensor.to(int).tolist())\n",
    "    prediction_test_df.to_csv(TEST_FILE_PATH)\n",
    "    logger.success(f\"Test predictions exported !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 18:50:28.570 | INFO     | __main__:evaluation:4 - START EVALUATION\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c610d52a8c6479e948b7ca2c5d61e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test batch...:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Input nan is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluation(model)\n",
      "File \u001b[0;32m~/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py?line=23'>24</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py?line=25'>26</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py?line=26'>27</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb Cell 42'\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000045vscode-remote?line=6'>7</a>\u001b[0m prediction_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000045vscode-remote?line=8'>9</a>\u001b[0m progress \u001b[39m=\u001b[39m tqdm(test_dataloader, desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtest batch...\u001b[39m\u001b[39m'\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000045vscode-remote?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_id, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(progress):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000045vscode-remote?line=10'>11</a>\u001b[0m     logger\u001b[39m.\u001b[39mtrace(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mbatch_id\u001b[39m=}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000045vscode-remote?line=11'>12</a>\u001b[0m     index_batch \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/tqdm/notebook.py:258\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/tqdm/notebook.py?line=255'>256</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/tqdm/notebook.py?line=256'>257</a>\u001b[0m     it \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[0;32m--> <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/tqdm/notebook.py?line=257'>258</a>\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m it:\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/tqdm/notebook.py?line=258'>259</a>\u001b[0m         \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/tqdm/notebook.py?line=259'>260</a>\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/tqdm/notebook.py?line=260'>261</a>\u001b[0m \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/tqdm/std.py?line=1191'>1192</a>\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/tqdm/std.py?line=1193'>1194</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/tqdm/std.py?line=1194'>1195</a>\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/tqdm/std.py?line=1195'>1196</a>\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/tqdm/std.py?line=1196'>1197</a>\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/tqdm/std.py?line=1197'>1198</a>\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=568'>569</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=569'>570</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=570'>571</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=571'>572</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb Cell 17'\u001b[0m in \u001b[0;36mJigsawDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000018vscode-remote?line=9'>10</a>\u001b[0m comment \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39miloc[index][\u001b[39m\"\u001b[39m\u001b[39mcomment_text\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000018vscode-remote?line=10'>11</a>\u001b[0m label \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39miloc[index][LABEL_LIST]\u001b[39m.\u001b[39mtolist(), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000018vscode-remote?line=12'>13</a>\u001b[0m token_list, attention_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtext_to_token_and_mask(comment)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000018vscode-remote?line=14'>15</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mdict\u001b[39m(index\u001b[39m=\u001b[39mindex, ids\u001b[39m=\u001b[39mtoken_list, mask\u001b[39m=\u001b[39mattention_mask, labels\u001b[39m=\u001b[39mlabel)\n",
      "\u001b[1;32m/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb Cell 17'\u001b[0m in \u001b[0;36mJigsawDataset.text_to_token_and_mask\u001b[0;34m(self, input_text)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000018vscode-remote?line=16'>17</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtext_to_token_and_mask\u001b[39m(\u001b[39mself\u001b[39m, input_text):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000018vscode-remote?line=17'>18</a>\u001b[0m     tokenization_dict \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39;49mencode_plus(input_text,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000018vscode-remote?line=18'>19</a>\u001b[0m                             add_special_tokens\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000018vscode-remote?line=19'>20</a>\u001b[0m                             max_length\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000018vscode-remote?line=20'>21</a>\u001b[0m                             padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmax_length\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000018vscode-remote?line=21'>22</a>\u001b[0m                             truncation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000018vscode-remote?line=22'>23</a>\u001b[0m                             return_attention_mask\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000018vscode-remote?line=23'>24</a>\u001b[0m                             return_tensors\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000018vscode-remote?line=24'>25</a>\u001b[0m     token_list \u001b[39m=\u001b[39m tokenization_dict[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B91.243.117.249/work2/home/ing1/corentin/hatespeech-detection-models/src/model/jigsaw2017-roberta-bce.ipynb#ch0000018vscode-remote?line=25'>26</a>\u001b[0m     attention_mask \u001b[39m=\u001b[39m tokenization_dict[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mflatten()\n",
      "File \u001b[0;32m~/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2556\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2545'>2546</a>\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2546'>2547</a>\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2547'>2548</a>\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2548'>2549</a>\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2552'>2553</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2553'>2554</a>\u001b[0m )\n\u001b[0;32m-> <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2555'>2556</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_encode_plus(\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2556'>2557</a>\u001b[0m     text\u001b[39m=\u001b[39;49mtext,\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2557'>2558</a>\u001b[0m     text_pair\u001b[39m=\u001b[39;49mtext_pair,\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2558'>2559</a>\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2559'>2560</a>\u001b[0m     padding_strategy\u001b[39m=\u001b[39;49mpadding_strategy,\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2560'>2561</a>\u001b[0m     truncation_strategy\u001b[39m=\u001b[39;49mtruncation_strategy,\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2561'>2562</a>\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2562'>2563</a>\u001b[0m     stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2563'>2564</a>\u001b[0m     is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2564'>2565</a>\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2565'>2566</a>\u001b[0m     return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2566'>2567</a>\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2567'>2568</a>\u001b[0m     return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2568'>2569</a>\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2569'>2570</a>\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2570'>2571</a>\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2571'>2572</a>\u001b[0m     return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2572'>2573</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2573'>2574</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=2574'>2575</a>\u001b[0m )\n",
      "File \u001b[0;32m~/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py:647\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=637'>638</a>\u001b[0m \u001b[39mif\u001b[39;00m return_offsets_mapping:\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=638'>639</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=639'>640</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mreturn_offset_mapping is not available when using Python tokenizers. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=640'>641</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo use this feature, change your tokenizer to one deriving from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=643'>644</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhttps://github.com/huggingface/transformers/pull/2674\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=644'>645</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=646'>647</a>\u001b[0m first_ids \u001b[39m=\u001b[39m get_input_ids(text)\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=647'>648</a>\u001b[0m second_ids \u001b[39m=\u001b[39m get_input_ids(text_pair) \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=649'>650</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_for_model(\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=650'>651</a>\u001b[0m     first_ids,\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=651'>652</a>\u001b[0m     pair_ids\u001b[39m=\u001b[39msecond_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=665'>666</a>\u001b[0m     verbose\u001b[39m=\u001b[39mverbose,\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=666'>667</a>\u001b[0m )\n",
      "File \u001b[0;32m~/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py:634\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus.<locals>.get_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=629'>630</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=630'>631</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m is not valid. Should be a string or a list/tuple of strings when `is_split_into_words=True`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=631'>632</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=632'>633</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=633'>634</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=634'>635</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=635'>636</a>\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Input nan is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers."
     ]
    }
   ],
   "source": [
    "evaluation(model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61bdec511af6d11ab513a76379a59f4e5a5400220f7b851eb051cbea952f89aa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
