{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torchmetrics as tm\n",
    "import torch\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "DATA_DIR_PATH = os.path.abspath(\"../../data\")\n",
    "SESSION_DIR_PATH = os.path.abspath(\"../../session\")\n",
    "TRAIN_DATASET_PATH = os.path.join(DATA_DIR_PATH, \"jigsaw2019-train.csv\")\n",
    "TEST_DATASET_PATH = os.path.join(DATA_DIR_PATH, \"jigsaw2019-test.csv\")\n",
    "LABEL_LIST = ['toxicity', 'obscene', 'sexual_explicit',\n",
    "            'identity_attack', 'insult', 'threat']\n",
    "IDENTITY_LIST = ['male', 'female', 'transgender', 'other_gender', 'heterosexual',\n",
    "                'homosexual_gay_or_lesbian', 'bisexual','other_sexual_orientation',\n",
    "                'christian', 'jewish', 'muslim', 'hindu','buddhist', 'atheist',\n",
    "                'other_religion', 'black', 'white', 'asian', 'latino',\n",
    "                'other_race_or_ethnicity', 'physical_disability',\n",
    "                'intellectual_or_learning_disability',\n",
    "                'psychiatric_or_mental_illness','other_disability']\n",
    "SELECTED_IDENTITY_LIST = ['male', 'female', 'black', 'white', 'homosexual_gay_or_lesbian',\n",
    "                    'christian', 'jewish', 'muslim', 'psychiatric_or_mental_illness']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "SESSION_NAME = \"roberta-pwbce_2022-03-28T17-41-19-543866\"\n",
    "CURRENT_SESSION_DIR_PATH = os.path.join(SESSION_DIR_PATH, SESSION_NAME)\n",
    "\n",
    "LOG_FILE_NAME = f\"{SESSION_NAME}.loguru.log\"\n",
    "MODEL_FILE_NAME = f\"{SESSION_NAME}.model\"\n",
    "TEST_FILE_NAME = f\"{SESSION_NAME}.test.csv\"\n",
    "VALIDATION_DATASET_NAME = f\"{SESSION_NAME}.jigsaw2019-validation.csv\"\n",
    "VALIDATION_FILE_NAME = f\"{SESSION_NAME}.validation.csv\"\n",
    "METRIC_FILE_NAME = f\"{SESSION_NAME}.metric.json\"\n",
    "LOG_FILE_PATH = os.path.join(CURRENT_SESSION_DIR_PATH, LOG_FILE_NAME)\n",
    "MODEL_FILE_PATH = os.path.join(CURRENT_SESSION_DIR_PATH, MODEL_FILE_NAME)\n",
    "TEST_FILE_PATH = os.path.join(CURRENT_SESSION_DIR_PATH, TEST_FILE_NAME)\n",
    "VALIDATION_DATASET_FILE_PATH = os.path.join(CURRENT_SESSION_DIR_PATH, VALIDATION_DATASET_NAME)\n",
    "VALIDATION_FILE_PATH = os.path.join(CURRENT_SESSION_DIR_PATH, VALIDATION_FILE_NAME)\n",
    "METRIC_FILE_PATH = os.path.join(CURRENT_SESSION_DIR_PATH, METRIC_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculer le meilleur seuil pour un F1 max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_validation_df = pd.read_csv(VALIDATION_DATASET_FILE_PATH, index_col=0)\n",
    "pred_validation_df = pd.read_csv(VALIDATION_FILE_PATH, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tensor = torch.Tensor(pred_validation_df[LABEL_LIST].to_numpy())\n",
    "target_tensor = torch.Tensor(target_validation_df[LABEL_LIST].to_numpy()).to(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2013322c6a7c4dc5a2bacead71c0bd30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_thresholds=0.761 \n",
      "float(best_f1)=0.39986997842788696\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(0, 1, 0.001)\n",
    "scores = [tm.F1Score(threshold=t)(pred_tensor, target_tensor) for t in tqdm(thresholds)]\n",
    "# get best threshold\n",
    "ix = np.argmax(scores)\n",
    "best_thresholds = thresholds[ix]\n",
    "best_f1 = scores[ix]\n",
    "print(f\"{best_thresholds=}\", f\"\\n{float(best_f1)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance sur le jeu de TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_df = pd.read_csv(TEST_FILE_PATH, index_col=0)\n",
    "target_test_df = pd.read_csv(TEST_DATASET_PATH, index_col=0)\n",
    "target_test_df[LABEL_LIST] = (target_test_df[LABEL_LIST] >= 0.5).astype(int)\n",
    "target_test_df = target_test_df[~target_test_df.white.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work2/home/ing1/corentin/hatespeech-detection-models/venv/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "accuracy = tm.Accuracy()\n",
    "f1score = tm.F1Score(threshold=0.5)\n",
    "recall = tm.Recall()\n",
    "precision = tm.Precision()\n",
    "auroc = tm.AUROC(num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= torch.Tensor(pred_test_df[LABEL_LIST].to_numpy())\n",
    "target= torch.Tensor((target_test_df[LABEL_LIST]>=0.5).astype(int).values).to(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : tensor(0.9042)\n",
      "F1 Score : tensor(0.3635)\n",
      "Precision : tensor(0.2403)\n",
      "Recall : tensor(0.7464)\n",
      "AUROC : tensor(0.9028)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy :\", accuracy(pred,target))\n",
    "print(\"F1 Score :\", f1score(pred,target))\n",
    "print(\"Precision :\", precision(pred,target))\n",
    "print(\"Recall :\", recall(pred,target))\n",
    "print(\"AUROC :\", auroc(pred,target))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61bdec511af6d11ab513a76379a59f4e5a5400220f7b851eb051cbea952f89aa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
